{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import json\n",
    "import os\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(v_name, data_video_path):\n",
    "    for videos in sorted(os.listdir(os.path.join(data_video_path, v_name))):\n",
    "        if len(videos.split('_')) != 1:\n",
    "            continue\n",
    "        for i in json.load(open(os.path.join(data_video_path, v_name, videos))):\n",
    "            json.dump([i], open(os.path.join(data_video_path, v_name, i['video']), 'w'))\n",
    "        ! rm $data_video_path/$v_name/$videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(episode_no, data_video_path, data_audio_path, type='train'):\n",
    "    \n",
    "    res = []\n",
    "    episode_str = f'output_episode{str(episode_no).zfill(2)}'\n",
    "    augmentations = ['', '_aug1', '_aug2'] if type == 'train' else ['']\n",
    "    if episode_no == 18:\n",
    "        augmentations = ['', '_aug1'] if type == 'train' else ['']\n",
    "\n",
    "    for aug in augmentations:\n",
    "        for (label, mode) in enumerate(['_nointeracs', '']):\n",
    "\n",
    "            path = f'{data_video_path}/{episode_str + mode + aug}'\n",
    "    \n",
    "            for v_feature in sorted(os.listdir(path)):\n",
    "                \n",
    "                curr_file = f'{path}/{v_feature}'\n",
    "                track1, track2, v = v_feature[5:].split('.')[0].split('_')\n",
    "\n",
    "                if int(track1) > int(track2):\n",
    "                    continue\n",
    "\n",
    "                extension = '.'.join(v_feature.split('.')[1:])\n",
    "                pair_loc = f'video{str(track2).zfill(3)}_{str(track1).zfill(3)}_{v}.{extension}'\n",
    "                pair_file = f'{path}/{pair_loc}'\n",
    "                audio_loc = f'audio_{str(track1).zfill(3)}_{str(track2).zfill(3)}_{v}_{label}.json'\n",
    "                audio_file = f'{data_audio_path}/episode{str(episode_no).zfill(2)}/{audio_loc}'\n",
    "\n",
    "                if os.path.getsize(curr_file) == 0:  continue\n",
    "                if (not os.path.isfile(pair_file)) or os.path.getsize(pair_file) == 0:\n",
    "                    continue\n",
    "                \n",
    "                feature1 = json.load(open(curr_file, 'rb'))\n",
    "                feature2 = json.load(open(pair_file, 'rb'))\n",
    "                feature_audio = json.load(open(audio_file)) if os.path.isfile(audio_file) else []\n",
    "\n",
    "                if feature1 == [] or feature2 == []: continue\n",
    "                assert len(feature1) == 1 and len(feature2) == 1\n",
    "\n",
    "                if len(feature1[0]['clips']) != len(feature2[0]['clips']):\n",
    "                    continue\n",
    "                \n",
    "                for (seg1, seg2) in zip(feature1[0]['clips'], feature2[0]['clips']):\n",
    "                    res.append((seg1['features'],\n",
    "                                seg2['features'],\n",
    "                                feature_audio,\n",
    "                                int(label)))\n",
    "                                \n",
    "    return res \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def create_type4_negative(data_video_path, data_audio_path, start, stop, n=10000):\n",
    "    res = []\n",
    "    \n",
    "    i = 0\n",
    "    while i < n:\n",
    "        ep_i = random.randint(start, stop)\n",
    "        ep_j = ep_i\n",
    "        while ep_j == ep_i: ep_j = random.randint(start, stop)\n",
    "\n",
    "        mode = random.choice(['', '_nointeracs'])\n",
    "        episode_stri,  episode_strj = f'episode{str(ep_i).zfill(2)}', f'episode{str(ep_j).zfill(2)}'\n",
    "        path_i = f'{data_video_path}/output_{episode_stri + mode}'\n",
    "        path_j = f'{data_video_path}/output_{episode_strj + mode}'\n",
    "\n",
    "        fi = random.choice(os.listdir(path_i))\n",
    "        file_i = os.path.join(path_i, fi)\n",
    "        file_j = os.path.join(path_j, random.choice(os.listdir(path_j)))\n",
    "\n",
    "        track1, track2, v = fi[5:].split('.')[0].split('_')\n",
    "        label = 1 if mode == '' else 0\n",
    "\n",
    "        audio_loc = f'audio_{str(track1).zfill(3)}_{str(track2).zfill(3)}_{v}_{label}.json'\n",
    "        audio_file = f'{data_audio_path}/episode{str(ep_i).zfill(2)}/{audio_loc}'\n",
    "\n",
    "        if os.path.isfile(audio_file):\n",
    "            feature_audio = json.load(open(audio_file))\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        featurei = json.load(open(file_i, 'rb'))\n",
    "        featurej = json.load(open(file_j, 'rb'))\n",
    "        if featurei == [] or featurej == []: continue\n",
    "\n",
    "        featurei[0]['clips']\n",
    "        res.append((random.choice(featurei[0]['clips']), random.choice(featurej[0]['clips']), feature_audio, label))\n",
    "\n",
    "        i += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_video_path = '../classification/outputs'\n",
    "data_audio_path = '../data/audio_features_final_april2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_data1 = []\n",
    "for episode_no in range(1, 19):\n",
    "    curr_data1 += create_dataset(episode_no, data_video_path, data_audio_path, type='train')\n",
    "curr_data1 += create_type4_negative(data_video_path, data_audio_path, 1, 19, 10000)\n",
    "json.dump(curr_data1, open(f'../data/dataset_with_audio/features_train.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_data2 = []\n",
    "for episode_no in range(19, 26):\n",
    "    curr_data2 += create_dataset(episode_no, data_video_path, data_audio_path, type='test')\n",
    "curr_data2 += create_type4_negative(data_video_path, data_audio_path, 1, 19, 3000)\n",
    "json.dump(curr_data2, open(f'../data/dataset_with_audio/features_valid.json', 'w'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9b19ba99e5cc9d7667e9def5e3b685457e6f043c7f1cffa7fbc2e0c702a98f9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
