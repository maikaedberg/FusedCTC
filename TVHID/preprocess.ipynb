{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import json\n",
    "import os\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set1(v_name):\n",
    "    action, number = v_name.split('_')\n",
    "    labels = {\n",
    "        'handShake': {2,14,15,16,18,19,20,21,24,25,26,27,28,32,40,41,42,43,44,45,46,47,48,49,50},\n",
    "\t    'highFive' : {1,6,7,8,9,10,11,12,13,23,24,25,27,28,29,30,31,32,33,34,35,44,45,47,48},\n",
    "\t    'hug'      : {2,3,4,11,12,15,16,17,18,20,21,27,29,30,31,32,33,34,35,36,42,44,46,49,50},\n",
    "\t    'kiss'\t   : {1,7,8,9,10,11,12,13,14,16,17,18,22,23,24,26,29,31,35,36,38,39,40,41,42},\n",
    "        'negative' : {i for i in range(1, 51)}\n",
    "    }\n",
    "    return (int(number) in labels[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "    'negative' : 0, \n",
    "    'handShake': 1,\n",
    "    'highFive' : 2,\n",
    "    'hug'      : 3,\n",
    "    'kiss'     : 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(v_name, data_video_path):\n",
    "    for videos in sorted(os.listdir(os.path.join(data_video_path, v_name))):\n",
    "        if len(videos.split('_')) != 1:\n",
    "            continue\n",
    "        for i in json.load(open(os.path.join(data_video_path, v_name, videos))):\n",
    "            json.dump([i], open(os.path.join(data_video_path, v_name, i['video']), 'w'))\n",
    "        ! rm $data_video_path/$v_name/$videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_video_path, data_audio_path):\n",
    "\n",
    "    datasets = [[], []]\n",
    "\n",
    "    for video in sorted(os.listdir(data_video_path)):\n",
    "    \n",
    "        audio_loc = os.path.join(data_audio_path, f'{video}.json')\n",
    "\n",
    "        if video[0] == '.': continue\n",
    "        #if '' != data_audio_path and video not in os.listdir(data_audio_path): continue\n",
    "\n",
    "        #    continue\n",
    "        set_no = int(not set1(video))\n",
    "\n",
    "        for track_name in sorted(os.listdir(os.path.join(data_video_path, video))):\n",
    "\n",
    "            if track_name[0] == '.': continue\n",
    "\n",
    "            track = track_name.split('.')[0]\n",
    "            extension = '.'.join(track_name.split('.')[1:])\n",
    "            lead, track1, track2, v, no_frames, interac_class = track.split('_')[:6]\n",
    "            if int(no_frames) < 2: continue\n",
    "\n",
    "            if 'aug2' in track: aug = 2\n",
    "            elif 'aug1' in track: aug = 1\n",
    "            else: aug = 0\n",
    "\n",
    "            if int(track1) > int(track2):\n",
    "                continue\n",
    "\n",
    "            to_join = [lead, track2, track1, v, no_frames, interac_class]            \n",
    "            if aug: to_join.append(f'aug{aug}')\n",
    "            pair_name = f\"{'_'.join(to_join)}.{extension}\"\n",
    "\n",
    "            file_loc = os.path.join(data_video_path, video, track_name)\n",
    "            pair_loc = os.path.join(data_video_path, video, pair_name)\n",
    "            audio_name = f\"{'_'.join([lead, track1, track2, v, no_frames, interac_class])}.mp4\"\n",
    "            audio_loc = os.path.join(data_audio_path, video, audio_name)\n",
    "\n",
    "            if os.path.getsize(file_loc) == 0:  continue\n",
    "            if (not os.path.isfile(pair_loc)) or os.path.getsize(pair_loc) == 0:  continue\n",
    "            if not os.path.isfile(audio_loc): continue\n",
    "\n",
    "            feature1 = json.load(open(file_loc, 'rb'))\n",
    "            feature2 = json.load(open(pair_loc, 'rb'))\n",
    "\n",
    "            feature_audio = json.load(open(audio_loc))\n",
    "\n",
    "\n",
    "            if feature1 == [] or feature2 == []:\n",
    "                continue\n",
    "            assert len(feature1) == 1 and len(feature2) == 1\n",
    "\n",
    "            video_name = feature1[0]['video']\n",
    "            if video_name != f'{track}.mp4':\n",
    "                continue\n",
    "\n",
    "            pair_name = f\"{'_'.join([lead, track2, track1, v, no_frames, interac_class])}.mp4\"\n",
    "            \n",
    "            for (seg1, seg2) in zip(feature1[0]['clips'], feature2[0]['clips']):\n",
    "                datasets[set_no].append((seg1['features'],\n",
    "                                         seg2['features'],\n",
    "                                         feature_audio,\n",
    "                                         int(interac_class)))\n",
    "\n",
    "            assert len(feature1[0]['clips']) == len(feature2[0]['clips']) \n",
    "            \n",
    "    return datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(episode_no, data_video_path, data_audio_path, type='train'):\n",
    "    \n",
    "    res = []\n",
    "    episode_str = f'output_episode{str(episode_no).zfill(2)}'\n",
    "    augmentations = ['', '_aug1', '_aug2'] if type == 'train' else ['']\n",
    "    if episode_no == 18:\n",
    "        augmentations = ['', '_aug1'] if type == 'train' else ['']\n",
    "\n",
    "    for aug in augmentations:\n",
    "        for (label, mode) in enumerate(['_nointeracs', '']):\n",
    "\n",
    "            path = f'{data_video_path}/{episode_str + mode + aug}'\n",
    "    \n",
    "            for v_feature in sorted(os.listdir(path)):\n",
    "                \n",
    "                curr_file = f'{path}/{v_feature}'\n",
    "                track1, track2, v = v_feature[5:].split('.')[0].split('_')\n",
    "\n",
    "                if int(track1) > int(track2):\n",
    "                    continue\n",
    "\n",
    "                extension = '.'.join(v_feature.split('.')[1:])\n",
    "                pair_loc = f'video{str(track2).zfill(3)}_{str(track1).zfill(3)}_{v}.{extension}'\n",
    "                pair_file = f'{path}/{pair_loc}'\n",
    "                audio_loc = f'audio_{str(track1).zfill(3)}_{str(track2).zfill(3)}_{v}_{label}.json'\n",
    "                audio_file = f'{data_audio_path}/episode{str(episode_no).zfill(2)}/{audio_loc}'\n",
    "\n",
    "                if os.path.getsize(curr_file) == 0:  continue\n",
    "                if (not os.path.isfile(pair_file)) or os.path.getsize(pair_file) == 0:\n",
    "                    continue\n",
    "                \n",
    "                feature1 = json.load(open(curr_file, 'rb'))\n",
    "                feature2 = json.load(open(pair_file, 'rb'))\n",
    "                feature_audio = json.load(open(audio_file)) if os.path.isfile(audio_file) else []\n",
    "\n",
    "                if feature1 == [] or feature2 == []: continue\n",
    "                assert len(feature1) == 1 and len(feature2) == 1\n",
    "\n",
    "                if len(feature1[0]['clips']) != len(feature2[0]['clips']):\n",
    "                    continue\n",
    "                \n",
    "                for (seg1, seg2) in zip(feature1[0]['clips'], feature2[0]['clips']):\n",
    "                    res.append((seg1['features'],\n",
    "                                seg2['features'],\n",
    "                                feature_audio,\n",
    "                                int(label)))\n",
    "                                \n",
    "    return res \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_video_path = f'../classification/features/output'\n",
    "data_audio_path = f'../data/audio_features'\n",
    "\n",
    "datasets = create_dataset(data_video_path, data_audio_path)\n",
    "for i in range(2):\n",
    "    json.dump(datasets[i], open(f'../data/video_dataset/features_set{i + 1}_valid.json', 'w'))\n",
    "    print(len(datasets[i]))\n",
    "\n",
    "datasets_aug1 = create_dataset(data_video_path + '_aug1', data_audio_path)\n",
    "datasets_aug2 = create_dataset(data_video_path + '_aug2', data_audio_path)\n",
    "\n",
    "for i in range(2):\n",
    "    json.dump(datasets[i] + datasets_aug1[i] + datasets_aug2[i],\n",
    "                open(f'../data/video_dataset/features_set{i + 1}_train.json', 'w'))\n",
    "    print(len(datasets_aug1[i]), len(datasets_aug2[i]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9b19ba99e5cc9d7667e9def5e3b685457e6f043c7f1cffa7fbc2e0c702a98f9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
